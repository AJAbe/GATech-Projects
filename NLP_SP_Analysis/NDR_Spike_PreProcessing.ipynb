{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aaa2255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re as re\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words('english')\n",
    "\n",
    "import pyLDAvis.gensim_models\n",
    "pyLDAvis.enable_notebook()# Visualise inside a notebook\n",
    "#import en_core_web_md\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.models import CoherenceModel\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from gensim import corpora\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from spacy.attrs import ORTH, NORM\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "import contractions\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from autocorrect import Speller\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e378c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are new keywords encountered that are a mix of letters and numbers, it would be beneficial to create special tokenizer classes for it\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.tokenizer.add_special_case('5g', [{ORTH: '5g', NORM: '5g'}])\n",
    "nlp.tokenizer.add_special_case('2g', [{ORTH: '2g', NORM: '2g'}])\n",
    "nlp.tokenizer.add_special_case('3g', [{ORTH: '3g', NORM: '3g'}])\n",
    "nlp.tokenizer.add_special_case('4g', [{ORTH: '4g', NORM: '4g'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbad142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please add more stop words here as and when they are encountered\n",
    "\n",
    "stops_list =['table_end','table_start','president','vice','business','chief','exerience','mhz','usa','senior','www','world',\\\n",
    "'january','february','march',\\\n",
    "'april','may','june','july','august','september','october','november','december','year','mr','north','america','industry',\\\n",
    "'payment','solution','solutions','i','ii','iii','iv','v','vi','vii','viii','company','product','management','customer',\\\n",
    "'item','ability','access','annual','report','broad','related','system','service','uncertain','unauthorized','false',\\\n",
    "'system','uk','revenue','earning','approval','region','example','incident','company','financial','statements','supplementary',\\\n",
    "'data','summary','notes','consolidated','note','notes','due', 'adjusted','review','versus','herein','reference','industrial', \\\n",
    "             'products','overall','result'\\\n",
    "            ]\n",
    "stops=stops+stops_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9ddd600",
   "metadata": {},
   "outputs": [],
   "source": [
    "item1_data=pd.read_csv(\"sp500_item1_sec_filings_0.txt\", delimiter=\"|\", parse_dates=['date'])\n",
    "item1a_data=pd.read_csv(\"sp500_item1a_sec_filings_0.txt\", delimiter=\"|\", parse_dates=['date'])\n",
    "item7_data=pd.read_csv(\"sp500_item7_sec_filings_0.txt\", delimiter=\"|\", parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aad7ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "item1_data[\"date\"]=pd.to_datetime(item1_data[\"date\"] , utc=True)\n",
    "item1_data['year']=item1_data[\"date\"].dt.year # Extract year\n",
    "item1_data[\"date\"]=item1_data[\"date\"].dt.date\n",
    "\n",
    "item1a_data[\"date\"]=pd.to_datetime(item1a_data[\"date\"] , utc=True)\n",
    "item1a_data['year']=item1a_data[\"date\"].dt.year\n",
    "item1a_data[\"date\"]=item1a_data[\"date\"].dt.date\n",
    "\n",
    "item7_data[\"date\"]=pd.to_datetime(item7_data[\"date\"] , utc=True)\n",
    "item7_data['year']=item7_data[\"date\"].dt.year\n",
    "item7_data[\"date\"]=item7_data[\"date\"].dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c32a6b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "item1_data.drop_duplicates(subset=['cik','date'], keep='last', inplace=True, ignore_index=True) # Remove duplicates\n",
    "item1a_data.drop_duplicates(subset=['cik','date'], keep='last', inplace=True, ignore_index=True)\n",
    "item7_data.drop_duplicates(subset=['cik','date'], keep='last', inplace=True, ignore_index=True)\n",
    "\n",
    "\n",
    "merged_stage1 = pd.merge(item1_data, item1a_data[['cik','date','company','item1A']], on=[\"cik\",\"date\"], how=\"inner\")\n",
    "final_merge=pd.merge(merged_stage1, item7_data[['cik','date','company','item7']], on=[\"cik\",\"date\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59ca0e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajaco\\AppData\\Local\\Temp\\ipykernel_9784\\1201314047.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_merge_1.drop(['item7','item1A', 'company_y','company_x','link'], axis=1,inplace=True)\n",
      "C:\\Users\\ajaco\\AppData\\Local\\Temp\\ipykernel_9784\\1201314047.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_merge_1A.drop(['item7','item1','company_y','company_x','link'], axis=1,inplace=True)\n",
      "C:\\Users\\ajaco\\AppData\\Local\\Temp\\ipykernel_9784\\1201314047.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_merge_7.drop(['item1','item1A','company_y','company_x','link'], axis=1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "final_merge_1= final_merge.dropna(subset=['year', 'item1']) #14718\n",
    "final_merge_1.drop(['item7','item1A', 'company_y','company_x','link'], axis=1,inplace=True)\n",
    "\n",
    "final_merge_1A= final_merge.dropna(subset=['year', 'item1A']) #11400\n",
    "final_merge_1A.drop(['item7','item1','company_y','company_x','link'], axis=1,inplace=True)\n",
    "\n",
    "final_merge_7= final_merge.dropna(subset=['year', 'item7']) #14667\n",
    "final_merge_7.drop(['item1','item1A','company_y','company_x','link'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49db1ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>cik</th>\n",
       "      <th>year</th>\n",
       "      <th>item1A</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-09</td>\n",
       "      <td>10-K</td>\n",
       "      <td>66740</td>\n",
       "      <td>2022</td>\n",
       "      <td>Item 1A. Risk Factors Provided below is a cau...</td>\n",
       "      <td>3M CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>10-K</td>\n",
       "      <td>66740</td>\n",
       "      <td>2021</td>\n",
       "      <td>Item 1A. Risk Factors  Provided below is a ca...</td>\n",
       "      <td>3M CO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  type    cik  year  \\\n",
       "0  2022-02-09  10-K  66740  2022   \n",
       "1  2021-02-04  10-K  66740  2021   \n",
       "\n",
       "                                              item1A company  \n",
       "0   Item 1A. Risk Factors Provided below is a cau...   3M CO  \n",
       "1   Item 1A. Risk Factors  Provided below is a ca...   3M CO  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merge_1A.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0623421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "addition = ['ADJ','NOUN', 'PROPN'] #capture tokens that are either Nouns, Proper Nouns or Adjectives\n",
    "\n",
    "\n",
    "def parse_document(doc):\n",
    "    \n",
    "    clean_tweet = re.sub(\"#[A-Za-z0-9_]+\",\"\", doc) # Remove Hash words\n",
    "    clean_tweet = re.sub(\"(?:(?:https?|ftp):\\\\/\\\\/)?[\\\\w/\\\\-?=%.]+\\\\.[\\\\w/\\\\-&?=%.]+\", \"\", clean_tweet) #Remove URL's\n",
    "    new_tweet = re.sub('(?<!\\\\w)[!\"\\\\\\\\$%\\\\&/#\\'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<=>\\\\?@\\\\[\\\\\\\\\\\\]\\\\^_`\\\\{\\\\|\\\\}\\\\~](?!\\\\w)', \\\n",
    "                       \" \", clean_tweet) #Remove special characaters except if between words or numbers\n",
    "    expanded_words = []\n",
    "    expanded_words.append(contractions.fix(new_tweet)) #isn't to isnt cases\n",
    "    expanded_text = ' '.join(expanded_words)\n",
    "    words = expanded_text.split(' ')\n",
    "    new_words = ' '.join([x for x in words if (not x.isdigit() and not x.lower() in stops)  ])\n",
    "    \n",
    "    doc = nlp(str(new_words))\n",
    "    words = []\n",
    "    for i,sent in enumerate(doc.sents):\n",
    "        \n",
    "        for word in sent:\n",
    "            if len(word.text) >= 2 and word.pos_  in addition : # will still skip < 2 letter words \n",
    "                # adjectives, noun or proper nouns\n",
    "                lem = word.lemma_.lower()\n",
    "                words.append(lem)\n",
    "        \n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed582a78",
   "metadata": {},
   "source": [
    "# The below lines can take > 4 hours each depending on processing capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8b88734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajaco\\AppData\\Local\\Temp\\ipykernel_9784\\1403742092.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_merge_1['item1_cleaned'] = final_merge_1['item1'].apply(parse_document)\n"
     ]
    }
   ],
   "source": [
    "final_merge_1['item1_cleaned'] = final_merge_1['item1'].apply(parse_document)\n",
    "final_merge_1.to_pickle(\"item1_cleaned.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ac4d507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajaco\\AppData\\Local\\Temp\\ipykernel_9784\\3653667875.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_merge_1A['item1A_cleaned'] = final_merge_1A['item1A'].apply(parse_document)\n"
     ]
    }
   ],
   "source": [
    "final_merge_1A['item1A_cleaned'] = final_merge_1A['item1A'].apply(parse_document)\n",
    "final_merge_1A.to_pickle(\"item1A_cleaned.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e89efc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajaco\\AppData\\Local\\Temp\\ipykernel_9784\\3877132198.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_merge_7['item7_cleaned'] = final_merge_7['item7'].apply(parse_document)\n"
     ]
    }
   ],
   "source": [
    "nlp.max_length = 10_000_000\n",
    "final_merge_7['item7_cleaned'] = final_merge_7['item7'].apply(parse_document)\n",
    "final_merge_7.to_pickle(\"item7_cleaned.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bb0f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
